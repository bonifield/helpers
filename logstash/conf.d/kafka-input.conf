# the "simplicity" of Logstash makes it ideal for subscribing to desired Kafka topics, then relaying data into a SIEM, accounting platform, monitoring cluster, etc with very low effort

input {
	kafka {
		# note that a Kafka consumer uses group_id to indicate the consumer group, and topics as a list to pull from
		# this assumes SSL/TLS is enabled on Kafka, and keystores are configured on Logstash in /etc/logstash for demo purposes
		bootstrap_servers => "useast01.example.domain.internal:9093,useast02.example.domain.internal:9093,useast03.example.domain.internal:9093"
		group_id => "logstash_east"
		security_protocol => "SSL"
		ssl_truststore_location => "/etc/logstash/logstashkeystore.jks"
		ssl_truststore_password => "LOGSTASH_KEYSTORE_PASSWORD"
		# note these should realistically be different pipelines based on volume
		topics => ["packetbeat", "filebeat", "metricbeat", "winlogbeat", "auditbeat"]
	}
}

filter {}

output {
	# send data elsewhere (Elasticsearch, Splunk, etc)
	stdout { codec => json }
}
